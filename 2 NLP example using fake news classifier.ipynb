{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_formatted_code = \"# If you are using Google Collab you will need this cell\\ntry:\\n    %tensorflow_version 2.x\\nexcept Exception:\\n    import os\\n\\n    os.environ[\\\"CUDA_DEVICE_ORDER\\\"] = \\\"PCI_BUS_ID\\\"\\n    os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"1\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If you are using Google Collab you will need this cell\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    import os\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_formatted_code = \"# Change the SETUP = True if this is your fist run\\nSETUP = False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change the SETUP = True if this is your fist run\n",
    "SETUP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_formatted_code = \"if SETUP:\\n    !pip install -q -U toai==0.3.7\\n    !pip install -q -U nb_black\\n    !pip install -q -U tensorflow-datasets\\n    !pip install -q -U --no-deps tensorflow-addons\\n    !pip install -q -U tensorflow_hub\\n    print(__import__(\\\"toai\\\").__version__)\\n    print(__import__(\\\"tensorflow\\\").__version__)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if SETUP:\n",
    "    !pip install -q -U toai==0.3.7\n",
    "    !pip install -q -U nb_black\n",
    "    !pip install -q -U tensorflow-datasets\n",
    "    !pip install -q -U --no-deps tensorflow-addons\n",
    "    !pip install -q -U tensorflow_hub\n",
    "    print(__import__(\"toai\").__version__)\n",
    "    print(__import__(\"tensorflow\").__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_formatted_code = \"from toai.imports import *\\nfrom toai.utils import save_file, load_file\\nfrom toai.data import DataContainer, DataBundle\\nfrom toai.metrics import sparse_top_2_categorical_accuracy\\nfrom toai.models import save_keras_model, load_keras_model\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nimport tensorflow_hub as hub\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from toai.imports import *\n",
    "from toai.utils import save_file, load_file\n",
    "from toai.data import DataContainer, DataBundle\n",
    "from toai.metrics import sparse_top_2_categorical_accuracy\n",
    "from toai.models import save_keras_model, load_keras_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_formatted_code = \"DATA_DIR = Path(\\\"data/fake-news\\\")\\nTEMP_DIR = Path(\\\"temp/fake-news\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data/fake-news\")\n",
    "TEMP_DIR = Path(\"temp/fake-news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_formatted_code = \"if SETUP:\\n    shutil.rmtree(str(DATA_DIR), ignore_errors=True)\\n    shutil.rmtrbee(str(TEMP_DIR), ignore_errors=True)\\n    DATA_DIR.mkdir(parents=True)\\n    TEMP_DIR.mkdir(parents=True)\\n    kaggle.api.authenticate()\\n    kaggle.api.competition_download_files(competition=\\\"fake-news\\\", path=DATA_DIR)\\n    shutil.unpack_archive(str(DATA_DIR / \\\"fake-news.zip\\\"), DATA_DIR)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if SETUP:\n",
    "    shutil.rmtree(str(DATA_DIR), ignore_errors=True)\n",
    "    shutil.rmtrbee(str(TEMP_DIR), ignore_errors=True)\n",
    "    DATA_DIR.mkdir(parents=True)\n",
    "    TEMP_DIR.mkdir(parents=True)\n",
    "    kaggle.api.authenticate()\n",
    "    kaggle.api.competition_download_files(competition=\"fake-news\", path=DATA_DIR)\n",
    "    shutil.unpack_archive(str(DATA_DIR / \"fake-news.zip\"), DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_formatted_code = \"BATCH_SIZE = 32\\nAUTOTUNE = tf.data.experimental.AUTOTUNE\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset all the example are in one csv!\n",
    "\n",
    "--> easy data exploration using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_formatted_code = \"all_data = pd.read_csv(DATA_DIR / \\\"train.csv\\\", low_memory=False, index_col=\\\"id\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data = pd.read_csv(DATA_DIR / \"train.csv\", low_memory=False, index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20800 entries, 0 to 20799\n",
      "Data columns (total 4 columns):\n",
      "title     20242 non-null object\n",
      "author    18843 non-null object\n",
      "text      20761 non-null object\n",
      "label     20800 non-null int64\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 812.5+ KB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_formatted_code = \"all_data.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label is the only column that doesn't have missing labels, but there are missing titles, authors etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>20242</td>\n",
       "      <td>18843</td>\n",
       "      <td>20761</td>\n",
       "      <td>20800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>19803</td>\n",
       "      <td>4201</td>\n",
       "      <td>20386</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>The Dark Agenda Behind Globalism And Open Borders</td>\n",
       "      <td>Pam Key</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>5</td>\n",
       "      <td>243</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title   author   text  \\\n",
       "count                                               20242    18843  20761   \n",
       "unique                                              19803     4201  20386   \n",
       "top     The Dark Agenda Behind Globalism And Open Borders  Pam Key          \n",
       "freq                                                    5      243     75   \n",
       "mean                                                  NaN      NaN    NaN   \n",
       "std                                                   NaN      NaN    NaN   \n",
       "min                                                   NaN      NaN    NaN   \n",
       "25%                                                   NaN      NaN    NaN   \n",
       "50%                                                   NaN      NaN    NaN   \n",
       "75%                                                   NaN      NaN    NaN   \n",
       "max                                                   NaN      NaN    NaN   \n",
       "\n",
       "               label  \n",
       "count   20800.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean        0.500625  \n",
       "std         0.500012  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_formatted_code = \"all_data.describe(include=\\\"all\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label is a number (probably 0 for real news and 1 for fake news). The median is 1 so it seems like a rather balanced data set.\n",
    "\n",
    "There is quite a high cardinality on authors so we won't encode it as categorical variable, we just use it as string like the other ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
       "      <td>Daniel Nussbaum</td>\n",
       "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "      <td>Alissa J. Rubin</td>\n",
       "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Excerpts From a Draft Script for Donald Trump’...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald J. Trump is scheduled to make a highly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
       "      <td>Megan Twohey and Scott Shane</td>\n",
       "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "id                                                      \n",
       "0   House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1   FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                   Why the Truth Might Get You Fired   \n",
       "3   15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4   Iranian woman jailed for fictional unpublished...   \n",
       "5   Jackie Mason: Hollywood Would Love Trump if He...   \n",
       "6   Life: Life Of Luxury: Elton John’s 6 Favorite ...   \n",
       "7   Benoît Hamon Wins French Socialist Party’s Pre...   \n",
       "8   Excerpts From a Draft Script for Donald Trump’...   \n",
       "9   A Back-Channel Plan for Ukraine and Russia, Co...   \n",
       "\n",
       "                          author  \\\n",
       "id                                 \n",
       "0                  Darrell Lucus   \n",
       "1                Daniel J. Flynn   \n",
       "2             Consortiumnews.com   \n",
       "3                Jessica Purkiss   \n",
       "4                 Howard Portnoy   \n",
       "5                Daniel Nussbaum   \n",
       "6                            NaN   \n",
       "7                Alissa J. Rubin   \n",
       "8                            NaN   \n",
       "9   Megan Twohey and Scott Shane   \n",
       "\n",
       "                                                 text  label  \n",
       "id                                                            \n",
       "0   House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1   Ever get the feeling your life circles the rou...      0  \n",
       "2   Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3   Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4   Print \\nAn Iranian woman has been sentenced to...      1  \n",
       "5   In these trying times, Jackie Mason is the Voi...      0  \n",
       "6   Ever wonder how Britain’s most iconic pop pian...      1  \n",
       "7   PARIS  —   France chose an idealistic, traditi...      0  \n",
       "8   Donald J. Trump is scheduled to make a highly ...      0  \n",
       "9   A week before Michael T. Flynn resigned as nat...      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_formatted_code = \"all_data.head(10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_formatted_code = \"all_data[\\\"title\\\"].fillna(\\\"No Title\\\", inplace=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data[\"title\"].fillna(\"No Title\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_formatted_code = \"all_data[\\\"author\\\"].fillna(\\\"Anonymous\\\", inplace=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data[\"author\"].fillna(\"Anonymous\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_formatted_code = \"all_data[\\\"text\\\"].fillna(\\\"\\\", inplace=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data[\"text\"].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are still missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20800 entries, 0 to 20799\n",
      "Data columns (total 4 columns):\n",
      "title     20800 non-null object\n",
      "author    20800 non-null object\n",
      "text      20800 non-null object\n",
      "label     20800 non-null int64\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 812.5+ KB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_formatted_code = \"all_data.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10413\n",
       "0    10387\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_formatted_code = \"all_data[\\\"label\\\"].value_counts()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a balanced data set - yeah!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's concatenate the input into one big string. To just have 1 textual feature rather than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_formatted_code = \"all_data[\\\"message\\\"] = (\\n    all_data[\\\"author\\\"] + \\\" \\\" + all_data[\\\"title\\\"] + \\\" \\\" + all_data[\\\"text\\\"]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data[\"message\"] = (\n",
    "    all_data[\"author\"] + \" \" + all_data[\"title\"] + \" \" + all_data[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0        Darrell Lucus House Dem Aide: We Didn’t Even S...\n",
       "1        Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...\n",
       "2        Consortiumnews.com Why the Truth Might Get You...\n",
       "3        Jessica Purkiss 15 Civilians Killed In Single ...\n",
       "4        Howard Portnoy Iranian woman jailed for fictio...\n",
       "                               ...                        \n",
       "20795    Jerome Hudson Rapper T.I.: Trump a ’Poster Chi...\n",
       "20796    Benjamin Hoffman N.F.L. Playoffs: Schedule, Ma...\n",
       "20797    Michael J. de la Merced and Rachel Abrams Macy...\n",
       "20798    Alex Ansary NATO, Russia To Hold Parallel Exer...\n",
       "20799    David Swanson What Keeps the F-35 Alive   Davi...\n",
       "Name: message, Length: 20800, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_formatted_code = \"all_data[\\\"message\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data[\"message\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are classmethods usually used for?\n",
    "\n",
    "* as alternative initialisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_formatted_code = \"data_bundle = DataBundle.from_dataframe(\\n    dataframe=all_data, x_col=\\\"message\\\", y_col=\\\"label\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_bundle = DataBundle.from_dataframe(\n",
    "    dataframe=all_data, x_col=\"message\", y_col=\"label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the whole data into 3 parts (train 80%, validate 10% and test 10%). Set `random=False` so when we rerun the notebook we see exactly the same observations in the different sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_formatted_code = \"train_data, valid_data, test_data = DataBundle.split(\\n    data_bundle=data_bundle, fracs=(0.8, 0.1, 0.1), random=False\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data, valid_data, test_data = DataBundle.split(\n",
    "    data_bundle=data_bundle, fracs=(0.8, 0.1, 0.1), random=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_formatted_code = \"@attr.s(auto_attribs=True)\\nclass TextPreprocessor:\\n    max_length: int = 100\\n    default_value: str = b\\\"<pad>\\\"\\n\\n    def __call__(self, text: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\\n        text = tf.strings.regex_replace(text, b\\\"[^a-zA-Z']\\\", b\\\" \\\")\\n        text = tf.strings.lower(text)\\n        text = tf.strings.split(text)\\n        text = text[:, : self.max_length]\\n        return text.to_tensor(default_value=self.default_value), label\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@attr.s(auto_attribs=True)\n",
    "class TextPreprocessor:\n",
    "    max_length: int = 100\n",
    "    default_value: str = b\"<pad>\"\n",
    "\n",
    "    def __call__(self, text: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n",
    "        text = tf.strings.regex_replace(text, b\"[^a-zA-Z']\", b\" \")\n",
    "        # currently in deep learning it's actually advised not to so lower casing\n",
    "        # but if you have a small data set it might be helpful\n",
    "        text = tf.strings.lower(text)\n",
    "        # split text into words\n",
    "        text = tf.strings.split(text)\n",
    "        # limit how many words we want to consider\n",
    "        text = text[:, : self.max_length]\n",
    "        # convert from a ragged tensor to a tensor\n",
    "        # ragged tensor: length of the tensor can vary in size, 100 words in one message and 3 words in another\n",
    "        # tensor: all messages have the same amount of words (and fill with defualt_value mentioned above)\n",
    "        return text.to_tensor(default_value=self.default_value), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`__call__` enables us to say `TextPreprocessor()` and make use of default arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_formatted_code = \"base_dataset = (\\n    train_data.to_dataset()\\n    .shuffle(len(train_data))\\n    .batch(BATCH_SIZE)\\n    .map(TextPreprocessor(), num_parallel_calls=AUTOTUNE)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_dataset = (\n",
    "    train_data.to_dataset()\n",
    "    .shuffle(len(train_data))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(TextPreprocessor(), num_parallel_calls=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_formatted_code = \"def make_vocabulary(dataset):\\n    vocabulary = Counter()\\n    for x, _ in dataset:\\n        for review in x:\\n            vocabulary.update(review.numpy().tolist())\\n    return vocabulary\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_vocabulary(dataset):\n",
    "    vocabulary = Counter()\n",
    "    for x, _ in dataset:\n",
    "        for review in x:\n",
    "            vocabulary.update(review.numpy().tolist())\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_formatted_code = \"vocabulary = make_vocabulary(base_dataset)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocabulary = make_vocabulary(base_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53282"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_formatted_code = \"len(vocabulary)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'the', 88447),\n",
       " (b'<pad>', 84547),\n",
       " (b'of', 39225),\n",
       " (b'to', 38017),\n",
       " (b'a', 36034),\n",
       " (b'and', 31123),\n",
       " (b'in', 29604),\n",
       " (b's', 19674),\n",
       " (b'on', 17192),\n",
       " (b'that', 15916)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_formatted_code = \"vocabulary.most_common()[:10]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocabulary.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit vocabulary size to 50k, original size was 53k so we don't care about uncommon words.\n",
    "\n",
    "But we don't want the model to break if it comes around a word it doesn't know: when that happens hash the word and place the hash in one of the buckets (with which the vocabulary will be enlarged later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_formatted_code = \"VOCABULARY_SIZE = 50000\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VOCABULARY_SIZE = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_formatted_code = \"truncated_vocabulary = [\\n    word for word, count in vocabulary.most_common()[:VOCABULARY_SIZE]\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "truncated_vocabulary = [\n",
    "    word for word, count in vocabulary.most_common()[:VOCABULARY_SIZE]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_formatted_code = \"len(truncated_vocabulary)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(truncated_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_formatted_code = \"word_to_id = {word: index for index, word in enumerate(truncated_vocabulary)}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_to_id = {word: index for index, word in enumerate(truncated_vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "1296\n",
      "2313\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_formatted_code = \"for word in b\\\"get rich quick\\\".split():\\n    print(word_to_id.get(word) if word_to_id.get(word) is not None else VOCABULARY_SIZE)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for word in b\"get rich quick\".split():\n",
    "    print(word_to_id.get(word) if word_to_id.get(word) is not None else VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_formatted_code = \"words = tf.constant(truncated_vocabulary)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = tf.constant(truncated_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_formatted_code = \"word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 5000 out of vocabulary buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_formatted_code = \"n_oov_buckets = VOCABULARY_SIZE // 10\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_oov_buckets = VOCABULARY_SIZE // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_formatted_code = \"n_oov_buckets\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_oov_buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a dictionary to encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_formatted_code = \"table = tf.lookup.StaticVocabularyTable(\\n    tf.lookup.KeyValueTensorInitializer(words, word_ids), n_oov_buckets\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = tf.lookup.StaticVocabularyTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(words, word_ids), n_oov_buckets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test what happens when retrieving an unknown word?\n",
    "\n",
    "It returns something (as opposed to failing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=67769, shape=(1, 3), dtype=int64, numpy=array([[48645, 54568, 53087]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_formatted_code = \"table.lookup(tf.constant([b\\\"mooney baby, moooney\\\".split()]))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table.lookup(tf.constant([b\"mooney baby, moooney\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_formatted_code = \"@attr.s(auto_attribs=True)\\nclass WordEncoder:\\n    vocabulary_table: tf.lookup.StaticVocabularyTable\\n\\n    def __call__(self, text: tf.Tensor, labels: tf.Tensor) -> tf.Tensor:\\n        return self.vocabulary_table.lookup(text), labels\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@attr.s(auto_attribs=True)\n",
    "class WordEncoder:\n",
    "    vocabulary_table: tf.lookup.StaticVocabularyTable\n",
    "\n",
    "    def __call__(self, text: tf.Tensor, labels: tf.Tensor) -> tf.Tensor:\n",
    "        return self.vocabulary_table.lookup(text), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_formatted_code = \"train_dataset = (\\n    train_data.to_dataset()\\n    .shuffle(len(train_data))\\n    .batch(BATCH_SIZE)\\n    .map(TextPreprocessor(), num_parallel_calls=AUTOTUNE)\\n    .map(WordEncoder(vocabulary_table=table), num_parallel_calls=AUTOTUNE)\\n    .cache()\\n    .repeat()\\n    .prefetch(AUTOTUNE)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = (\n",
    "    train_data.to_dataset()\n",
    "    .shuffle(len(train_data))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(TextPreprocessor(), num_parallel_calls=AUTOTUNE)\n",
    "    .map(WordEncoder(vocabulary_table=table), num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_formatted_code = \"valid_dataset = (\\n    valid_data.to_dataset()\\n    .batch(BATCH_SIZE)\\n    .map(TextPreprocessor(), num_parallel_calls=AUTOTUNE)\\n    .map(WordEncoder(vocabulary_table=table), num_parallel_calls=AUTOTUNE)\\n    .cache()\\n    .prefetch(AUTOTUNE)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_dataset = (\n",
    "    valid_data.to_dataset()\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(TextPreprocessor(), num_parallel_calls=AUTOTUNE)\n",
    "    .map(WordEncoder(vocabulary_table=table), num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_formatted_code = \"test_dataset = (\\n    test_data.to_dataset()\\n    .batch(BATCH_SIZE)\\n    .map(TextPreprocessor(), num_parallel_calls=AUTOTUNE)\\n    .map(WordEncoder(vocabulary_table=table), num_parallel_calls=AUTOTUNE)\\n    .cache()\\n    .prefetch(AUTOTUNE)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = (\n",
    "    test_data.to_dataset()\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(TextPreprocessor(), num_parallel_calls=AUTOTUNE)\n",
    "    .map(WordEncoder(vocabulary_table=table), num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_formatted_code = \"data_container = DataContainer(\\n    base=train_dataset,\\n    train=train_dataset,\\n    train_steps=math.ceil(len(train_data) / BATCH_SIZE),\\n    validation=valid_dataset,\\n    test=test_dataset,\\n    label_map={0: 0, 1: 1},\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_container = DataContainer(\n",
    "    base=train_dataset,\n",
    "    train=train_dataset,\n",
    "    train_steps=math.ceil(len(train_data) / BATCH_SIZE),\n",
    "    validation=valid_dataset,\n",
    "    test=test_dataset,\n",
    "    label_map={0: 0, 1: 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if training data set got encoded correctly:\n",
    "\n",
    "With deep learning you don't get compile or run time errors.\n",
    "\n",
    "It's mostly that the training time takes forever --> and then need to check if the input/output shapes are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100)\n",
      "(32,)\n",
      "tf.Tensor(\n",
      "[  854  4193   171  5463  6152    12  6907  4730    33  4193   171  5463\n",
      "  6152    12  6907  4730    33   359    85   462   129   831  2911  4193\n",
      "   860   116   317   160 10274   594     5   181    81     7   116   404\n",
      "    42    12  1194   812    12 10245     5    32  8932     5  2703   127\n",
      "     2  7624    64 10826 13745     5   202  3750     0  4193   171  5463\n",
      "   404   160 10274    37    22    69   679   185     0    61    38  6907\n",
      "  3441    33   391  6038    46 10274  2946  1074     7   611  5073    37\n",
      "    22    69  1370     8     0  4193   171  2958   185     0    61    38\n",
      " 10484     9    12   159], shape=(100,), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_formatted_code = \"for x, y in data_container.train.take(1):\\n    print(x.shape)\\n    print(y.shape)\\n    print(x[0])\\n    print(y[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in data_container.train.take(1):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(x[0])\n",
    "    print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the number the more rare the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if validation data set got encoded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100)\n",
      "(32,)\n",
      "tf.Tensor(\n",
      "[ 5456  2192  1986    12 22702    46   348   293     5    24    85    20\n",
      "     0    96  4538   507   695   815  2581  5725  3902  3392  5726   631\n",
      "  4373  4546  5444     0 10044    60   217   312    10  1986    12     7\n",
      "   276   100   348     0   138    49    65     7   571   157   131   217\n",
      "  2114  5280    10  4033    46   341  1530    20     0  9261    20  2028\n",
      "   117    83    77  1595  1065    84  3399    10     0    12   100     0\n",
      "  1183   445    29  3927     3    46    65 22702   293    16   285   479\n",
      "    83    28  1178    10    54     3  1618    16    66    38     0   507\n",
      "    43    29    54 14209], shape=(100,), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_formatted_code = \"for x, y in data_container.validation.take(1):\\n    print(x.shape)\\n    print(y.shape)\\n    print(x[0])\\n    print(y[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in data_container.validation.take(1):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(x[0])\n",
    "    print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're gonna create a model from scratch (not using pretrained model).\n",
    "\n",
    "We do it here because the data is so balanced that this is gonna be a piece-of-cake.\n",
    "\n",
    "2-layer bi-directional LSTM with a GlobalMaxPool1D on top and a Dense layer at the end:\n",
    "* start with embedding layer to get a lower dimensional representation of the data (of a potentially sparse space) to extract latent features from the categorical variables\n",
    "    * embedding size 256 and inputs is the sum of vocabulary and the out-of-vocabulary buckets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_formatted_code = \"def make_lstm_model(n_categories, embedding_size, lstm_size, lstm_dropout, dropout):\\n    return keras.models.Sequential(\\n        [\\n            keras.layers.Embedding(\\n                VOCABULARY_SIZE + n_oov_buckets,\\n                embedding_size,\\n                mask_zero=True,\\n                input_shape=[None],\\n            ),\\n            keras.layers.Bidirectional(\\n                keras.layers.LSTM(\\n                    lstm_size, dropout=lstm_dropout, return_sequences=True\\n                )\\n            ),\\n            keras.layers.Bidirectional(\\n                keras.layers.LSTM(\\n                    lstm_size, dropout=lstm_dropout, return_sequences=True\\n                )\\n            ),\\n            keras.layers.GlobalMaxPool1D(),\\n            keras.layers.Dropout(dropout),\\n            keras.layers.Dense(n_categories, activation=keras.activations.softmax),\\n        ]\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_lstm_model(n_categories, embedding_size, lstm_size, lstm_dropout, dropout):\n",
    "    return keras.models.Sequential(\n",
    "        [\n",
    "            # extract latent features from the categorical variables\n",
    "            # usually you want the embeddings to be pretrained\n",
    "            keras.layers.Embedding(\n",
    "                VOCABULARY_SIZE + n_oov_buckets,\n",
    "                embedding_size,\n",
    "                # deals with padding to train faster\n",
    "                mask_zero=True,\n",
    "                # input shape can be anything\n",
    "                input_shape=[None],\n",
    "            ),\n",
    "            keras.layers.Bidirectional(\n",
    "                keras.layers.LSTM(\n",
    "                    lstm_size, dropout=lstm_dropout, return_sequences=True\n",
    "                )\n",
    "            ),\n",
    "            keras.layers.Bidirectional(\n",
    "                keras.layers.LSTM(\n",
    "                    lstm_size, dropout=lstm_dropout, return_sequences=True\n",
    "                )\n",
    "            ),\n",
    "            keras.layers.GlobalMaxPool1D(),\n",
    "            keras.layers.Dropout(dropout),\n",
    "            keras.layers.Dense(n_categories, activation=keras.activations.softmax),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_formatted_code = \"model = make_lstm_model(\\n    n_categories=data_container.n_classes,\\n    embedding_size=256,\\n    lstm_size=256,\\n    lstm_dropout=0.2,\\n    dropout=0.5,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = make_lstm_model(\n",
    "    n_categories=data_container.n_classes,\n",
    "    embedding_size=256,\n",
    "    lstm_size=256,\n",
    "    lstm_dropout=0.2,\n",
    "    dropout=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same loss and optimizer as for the computer vision example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_formatted_code = \"model.compile(\\n    loss=keras.losses.sparse_categorical_crossentropy,\\n    optimizer=keras.optimizers.Adam(lr=3e-4),\\n    metrics=[keras.metrics.sparse_categorical_accuracy],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
    "    metrics=[keras.metrics.sparse_categorical_accuracy],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 52 steps, validate for 65 steps\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 68s 1s/step - loss: 0.4972 - sparse_categorical_accuracy: 0.7464 - val_loss: 0.1838 - val_sparse_categorical_accuracy: 0.9365\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 35s 669ms/step - loss: 0.1665 - sparse_categorical_accuracy: 0.9441 - val_loss: 0.1181 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 33s 638ms/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.0872 - val_sparse_categorical_accuracy: 0.9731\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 34s 644ms/step - loss: 0.0996 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9764\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 34s 652ms/step - loss: 0.0975 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.0842 - val_sparse_categorical_accuracy: 0.9760\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 33s 641ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9772 - val_loss: 0.0706 - val_sparse_categorical_accuracy: 0.9803\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 33s 640ms/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0665 - val_sparse_categorical_accuracy: 0.9812\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 34s 645ms/step - loss: 0.0662 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.0621 - val_sparse_categorical_accuracy: 0.9832\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 33s 635ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.0609 - val_sparse_categorical_accuracy: 0.9837\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 34s 645ms/step - loss: 0.0518 - sparse_categorical_accuracy: 0.9874 - val_loss: 0.0592 - val_sparse_categorical_accuracy: 0.9832\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 33s 638ms/step - loss: 0.0226 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0621 - val_sparse_categorical_accuracy: 0.9827\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 33s 633ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9837\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 33s 637ms/step - loss: 0.0098 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0590 - val_sparse_categorical_accuracy: 0.9851\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 33s 642ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0591 - val_sparse_categorical_accuracy: 0.9851\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 33s 638ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.0588 - val_sparse_categorical_accuracy: 0.9851\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 33s 637ms/step - loss: 0.0231 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0577 - val_sparse_categorical_accuracy: 0.9846\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 33s 629ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.0578 - val_sparse_categorical_accuracy: 0.9846\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 33s 628ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0578 - val_sparse_categorical_accuracy: 0.9846\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 33s 632ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0578 - val_sparse_categorical_accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_formatted_code = \"history = model.fit(\\n    data_container.train,\\n    steps_per_epoch=data_container.train_steps // 10,\\n    validation_data=data_container.validation,\\n    epochs=20,\\n    callbacks=[\\n        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\\n        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\\n    ],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    data_container.train,\n",
    "    steps_per_epoch=data_container.train_steps // 10,\n",
    "    validation_data=data_container.validation,\n",
    "    epochs=20,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
    "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After network has seen all data accuracy is `val_sparse_categorical_accuracy: 0.9846` - pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 8s 131ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05768993731874686, 0.9846154]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_formatted_code = \"model.evaluate(data_container.validation)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(data_container.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1047\n",
      "           1       0.99      0.98      0.98      1033\n",
      "\n",
      "    accuracy                           0.98      2080\n",
      "   macro avg       0.98      0.98      0.98      2080\n",
      "weighted avg       0.98      0.98      0.98      2080\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_formatted_code = \"print(\\n    classification_report(\\n        [y.numpy() for _, y in data_container.validation.unbatch()],\\n        model.predict(data_container.validation).argmax(axis=1),\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        [y.numpy() for _, y in data_container.validation.unbatch()],\n",
    "        model.predict(data_container.validation).argmax(axis=1),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results look good, we're not worried about any class imbalances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the cases when this is not enough, turn to tensorflow hub:\n",
    "\n",
    "* pretrained embedding layers\n",
    "* pretrained language models\n",
    "\n",
    "Also note, using the pretrained embedding layers you can feed the training data in pretty raw (no tolenization, no shuffling, and whatever else we did for computer vision.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_formatted_code = \"train_dataset = (\\n    train_data.to_dataset()\\n    .shuffle(len(train_data))\\n    .batch(BATCH_SIZE)\\n    .cache()\\n    .repeat()\\n    .prefetch(AUTOTUNE)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = (\n",
    "    train_data.to_dataset()\n",
    "    .shuffle(len(train_data))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_formatted_code = \"valid_dataset = valid_data.to_dataset().batch(BATCH_SIZE).cache().prefetch(AUTOTUNE)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_dataset = valid_data.to_dataset().batch(BATCH_SIZE).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_formatted_code = \"test_dataset = test_data.to_dataset().batch(BATCH_SIZE).cache().prefetch(AUTOTUNE)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test_data.to_dataset().batch(BATCH_SIZE).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_formatted_code = \"data_container = DataContainer(\\n    base=train_dataset,\\n    train=train_dataset,\\n    train_steps=math.ceil(len(train_data) / BATCH_SIZE),\\n    validation=valid_dataset,\\n    test=test_dataset,\\n    label_map={0: 0, 1: 1},\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_container = DataContainer(\n",
    "    base=train_dataset,\n",
    "    train=train_dataset,\n",
    "    train_steps=math.ceil(len(train_data) / BATCH_SIZE),\n",
    "    validation=valid_dataset,\n",
    "    test=test_dataset,\n",
    "    label_map={0: 0, 1: 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the pretrained embedding:\n",
    "\n",
    "(spoiler will get us to `val_sparse_categorical_accuracy: 0.9928`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_formatted_code = \"def train_model(\\n    model,\\n    data_container,\\n    epochs,\\n    lrs=None,\\n    optimizers=None,\\n    patience=5,\\n    class_weights=None,\\n    verbose=1,\\n    log_dir=str(TEMP_DIR / \\\"logs\\\"),\\n):\\n    if optimizers is None:\\n        optimizers = [keras.optimizers.Adam(lr) for lr in lrs]\\n    model.compile(\\n        loss=keras.losses.sparse_categorical_crossentropy,\\n        optimizer=optimizers[0],\\n        metrics=[keras.metrics.sparse_categorical_accuracy],\\n    )\\n    model.fit(\\n        data_container.train,\\n        steps_per_epoch=data_container.train_steps,\\n        validation_data=data_container.validation,\\n        epochs=epochs[0],\\n        callbacks=[\\n            keras.callbacks.ReduceLROnPlateau(patience=patience, factor=0.3),\\n            keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\\n        ],\\n        class_weight=class_weights,\\n        verbose=verbose,\\n    )\\n    model.layers[0].trainable = True\\n    model.compile(\\n        loss=keras.losses.sparse_categorical_crossentropy,\\n        optimizer=optimizers[1],\\n        metrics=[keras.metrics.sparse_categorical_accuracy],\\n    )\\n    model.fit(\\n        data_container.train,\\n        steps_per_epoch=data_container.train_steps,\\n        validation_data=data_container.validation,\\n        epochs=epochs[1],\\n        callbacks=[\\n            keras.callbacks.ReduceLROnPlateau(patience=patience // 2, factor=0.3),\\n            keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\\n            keras.callbacks.TensorBoard(log_dir=log_dir),\\n        ],\\n        class_weight=class_weights,\\n        verbose=verbose,\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    data_container,\n",
    "    epochs,\n",
    "    lrs=None,\n",
    "    optimizers=None,\n",
    "    patience=5,\n",
    "    class_weights=None,\n",
    "    verbose=1,\n",
    "    log_dir=str(TEMP_DIR / \"logs\"),\n",
    "):\n",
    "    if optimizers is None:\n",
    "        optimizers = [keras.optimizers.Adam(lr) for lr in lrs]\n",
    "    model.compile(\n",
    "        loss=keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer=optimizers[0],\n",
    "        metrics=[keras.metrics.sparse_categorical_accuracy],\n",
    "    )\n",
    "    model.fit(\n",
    "        data_container.train,\n",
    "        steps_per_epoch=data_container.train_steps,\n",
    "        validation_data=data_container.validation,\n",
    "        epochs=epochs[0],\n",
    "        callbacks=[\n",
    "            keras.callbacks.ReduceLROnPlateau(patience=patience, factor=0.3),\n",
    "            keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "        ],\n",
    "        class_weight=class_weights,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    model.layers[0].trainable = True\n",
    "    model.compile(\n",
    "        loss=keras.losses.sparse_categorical_crossentropy,\n",
    "        optimizer=optimizers[1],\n",
    "        metrics=[keras.metrics.sparse_categorical_accuracy],\n",
    "    )\n",
    "    model.fit(\n",
    "        data_container.train,\n",
    "        steps_per_epoch=data_container.train_steps,\n",
    "        validation_data=data_container.validation,\n",
    "        epochs=epochs[1],\n",
    "        callbacks=[\n",
    "            keras.callbacks.ReduceLROnPlateau(patience=patience // 2, factor=0.3),\n",
    "            keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "            keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "        ],\n",
    "        class_weight=class_weights,\n",
    "        verbose=verbose,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_formatted_code = \"def make_hub_model(url, n_categories):\\n    return keras.Sequential(\\n        [\\n            hub.KerasLayer(url, dtype=tf.string, input_shape=[]),\\n            keras.layers.Dropout(0.5),\\n            keras.layers.Dense(n_categories, activation=keras.activations.softmax),\\n        ]\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_hub_model(url, n_categories):\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            hub.KerasLayer(url, dtype=tf.string, input_shape=[]),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(n_categories, activation=keras.activations.softmax),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_formatted_code = \"def run_models(urls, data_container, class_weights):\\n    for url in urls:\\n        model = make_hub_model(url, data_container.n_classes)\\n        model_name = f\\\"{url.split('/')[4]}\\\"\\n        print(f\\\" {model_name} \\\".center(80, \\\"=\\\"))\\n        shutil.rmtree(str(TEMP_DIR / model_name), ignore_errors=True)\\n        train_model(\\n            model=model,\\n            data_container=data_container,\\n            epochs=[25, 15],\\n            optimizers=[keras.optimizers.Adam(lr=3e-4), keras.optimizers.Adam(lr=1e-4)],\\n            class_weights=class_weights,\\n            patience=4,\\n            verbose=2,\\n            log_dir=str(TEMP_DIR / model_name),\\n        )\\n        model.save(f\\\"{TEMP_DIR / model_name}.h5\\\")\\n        save_keras_model(\\n            model,\\n            str(TEMP_DIR / model_name / \\\"architecture\\\"),\\n            str(TEMP_DIR / model_name / \\\"weights\\\"),\\n        )\\n        keras.backend.clear_session()\\n        del model\\n        keras.backend.clear_session()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_models(urls, data_container, class_weights):\n",
    "    for url in urls:\n",
    "        model = make_hub_model(url, data_container.n_classes)\n",
    "        model_name = f\"{url.split('/')[4]}\"\n",
    "        print(f\" {model_name} \".center(80, \"=\"))\n",
    "        shutil.rmtree(str(TEMP_DIR / model_name), ignore_errors=True)\n",
    "        train_model(\n",
    "            model=model,\n",
    "            data_container=data_container,\n",
    "            epochs=[25, 15],\n",
    "            optimizers=[keras.optimizers.Adam(lr=3e-4), keras.optimizers.Adam(lr=1e-4)],\n",
    "            class_weights=class_weights,\n",
    "            patience=4,\n",
    "            verbose=2,\n",
    "            log_dir=str(TEMP_DIR / model_name),\n",
    "        )\n",
    "        model.save(f\"{TEMP_DIR / model_name}.h5\")\n",
    "        save_keras_model(\n",
    "            model,\n",
    "            str(TEMP_DIR / model_name / \"architecture\"),\n",
    "            str(TEMP_DIR / model_name / \"weights\"),\n",
    "        )\n",
    "        keras.backend.clear_session()\n",
    "        del model\n",
    "        keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_formatted_code = \"def evaluate_models(urls, data_container):\\n    reports = {}\\n    for url in urls:\\n        model_name = f\\\"{url.split('/')[4]}\\\"\\n        print(f\\\" {model_name} \\\".center(80, \\\"=\\\"))\\n        try:\\n            model = keras.model.load_model(\\n                f\\\"{TEMP_DIR / model_name}.h5\\\",\\n                custom_objects={\\\"KerasLayer\\\": hub.KerasLayer},\\n            )\\n        except:\\n            print(f\\\"Loading architecture & weights separately\\\")\\n            model = load_keras_model(\\n                str(TEMP_DIR / model_name / \\\"architecture\\\"),\\n                str(TEMP_DIR / model_name / \\\"weights\\\"),\\n                custom_objects={\\\"KerasLayer\\\": hub.KerasLayer},\\n            )\\n        reports[model_name] = classification_report(\\n            [\\n                label.numpy()\\n                for _, label in data_container.validation.take(-1).unbatch()\\n            ],\\n            model.predict(data_container.validation).argmax(axis=1),\\n        )\\n        del model\\n    return reports\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_models(urls, data_container):\n",
    "    reports = {}\n",
    "    for url in urls:\n",
    "        model_name = f\"{url.split('/')[4]}\"\n",
    "        print(f\" {model_name} \".center(80, \"=\"))\n",
    "        try:\n",
    "            model = keras.model.load_model(\n",
    "                f\"{TEMP_DIR / model_name}.h5\",\n",
    "                custom_objects={\"KerasLayer\": hub.KerasLayer},\n",
    "            )\n",
    "        except:\n",
    "            print(f\"Loading architecture & weights separately\")\n",
    "            model = load_keras_model(\n",
    "                str(TEMP_DIR / model_name / \"architecture\"),\n",
    "                str(TEMP_DIR / model_name / \"weights\"),\n",
    "                custom_objects={\"KerasLayer\": hub.KerasLayer},\n",
    "            )\n",
    "        reports[model_name] = classification_report(\n",
    "            [\n",
    "                label.numpy()\n",
    "                for _, label in data_container.validation.take(-1).unbatch()\n",
    "            ],\n",
    "            model.predict(data_container.validation).argmax(axis=1),\n",
    "        )\n",
    "        del model\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to tensorflow hub to pick pretrained language models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_formatted_code = \"model_urls = (\\n    \\\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\\\",\\n    \\\"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_urls = (\n",
    "    \"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\",\n",
    "    \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Wiki-words-250-with-normalization =======================\n",
      "Train for 520 steps, validate for 65 steps\n",
      "Epoch 1/25\n",
      "520/520 - 15s - loss: 0.8740 - sparse_categorical_accuracy: 0.5410 - val_loss: 0.5967 - val_sparse_categorical_accuracy: 0.6476\n",
      "Epoch 2/25\n",
      "520/520 - 14s - loss: 0.6881 - sparse_categorical_accuracy: 0.6258 - val_loss: 0.5480 - val_sparse_categorical_accuracy: 0.7250\n",
      "Epoch 3/25\n",
      "520/520 - 13s - loss: 0.6067 - sparse_categorical_accuracy: 0.6812 - val_loss: 0.5277 - val_sparse_categorical_accuracy: 0.7543\n",
      "Epoch 4/25\n",
      "520/520 - 14s - loss: 0.5746 - sparse_categorical_accuracy: 0.7028 - val_loss: 0.5155 - val_sparse_categorical_accuracy: 0.7683\n",
      "Epoch 5/25\n",
      "520/520 - 14s - loss: 0.5533 - sparse_categorical_accuracy: 0.7225 - val_loss: 0.5057 - val_sparse_categorical_accuracy: 0.7678\n",
      "Epoch 6/25\n",
      "520/520 - 13s - loss: 0.5497 - sparse_categorical_accuracy: 0.7260 - val_loss: 0.4990 - val_sparse_categorical_accuracy: 0.7731\n",
      "Epoch 7/25\n",
      "520/520 - 14s - loss: 0.5420 - sparse_categorical_accuracy: 0.7312 - val_loss: 0.4942 - val_sparse_categorical_accuracy: 0.7760\n",
      "Epoch 8/25\n",
      "520/520 - 14s - loss: 0.5391 - sparse_categorical_accuracy: 0.7323 - val_loss: 0.4896 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 9/25\n",
      "520/520 - 13s - loss: 0.5330 - sparse_categorical_accuracy: 0.7406 - val_loss: 0.4859 - val_sparse_categorical_accuracy: 0.7812\n",
      "Epoch 10/25\n",
      "520/520 - 14s - loss: 0.5303 - sparse_categorical_accuracy: 0.7406 - val_loss: 0.4829 - val_sparse_categorical_accuracy: 0.7812\n",
      "Epoch 11/25\n",
      "520/520 - 14s - loss: 0.5348 - sparse_categorical_accuracy: 0.7388 - val_loss: 0.4816 - val_sparse_categorical_accuracy: 0.7793\n",
      "Epoch 12/25\n",
      "520/520 - 14s - loss: 0.5349 - sparse_categorical_accuracy: 0.7343 - val_loss: 0.4801 - val_sparse_categorical_accuracy: 0.7870\n",
      "Epoch 13/25\n",
      "520/520 - 13s - loss: 0.5288 - sparse_categorical_accuracy: 0.7418 - val_loss: 0.4780 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 14/25\n",
      "520/520 - 14s - loss: 0.5301 - sparse_categorical_accuracy: 0.7417 - val_loss: 0.4763 - val_sparse_categorical_accuracy: 0.7880\n",
      "Epoch 15/25\n",
      "520/520 - 14s - loss: 0.5325 - sparse_categorical_accuracy: 0.7326 - val_loss: 0.4761 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 16/25\n",
      "520/520 - 14s - loss: 0.5306 - sparse_categorical_accuracy: 0.7383 - val_loss: 0.4752 - val_sparse_categorical_accuracy: 0.7861\n",
      "Epoch 17/25\n",
      "520/520 - 14s - loss: 0.5265 - sparse_categorical_accuracy: 0.7410 - val_loss: 0.4744 - val_sparse_categorical_accuracy: 0.7889\n",
      "Epoch 18/25\n",
      "520/520 - 14s - loss: 0.5281 - sparse_categorical_accuracy: 0.7418 - val_loss: 0.4736 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 19/25\n",
      "520/520 - 14s - loss: 0.5311 - sparse_categorical_accuracy: 0.7384 - val_loss: 0.4730 - val_sparse_categorical_accuracy: 0.7870\n",
      "Epoch 20/25\n",
      "520/520 - 14s - loss: 0.5259 - sparse_categorical_accuracy: 0.7434 - val_loss: 0.4722 - val_sparse_categorical_accuracy: 0.7875\n",
      "Epoch 21/25\n",
      "520/520 - 14s - loss: 0.5291 - sparse_categorical_accuracy: 0.7415 - val_loss: 0.4717 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 22/25\n",
      "520/520 - 14s - loss: 0.5262 - sparse_categorical_accuracy: 0.7389 - val_loss: 0.4713 - val_sparse_categorical_accuracy: 0.7889\n",
      "Epoch 23/25\n",
      "520/520 - 14s - loss: 0.5278 - sparse_categorical_accuracy: 0.7388 - val_loss: 0.4709 - val_sparse_categorical_accuracy: 0.7856\n",
      "Epoch 24/25\n",
      "520/520 - 14s - loss: 0.5267 - sparse_categorical_accuracy: 0.7384 - val_loss: 0.4707 - val_sparse_categorical_accuracy: 0.7894\n",
      "Epoch 25/25\n",
      "520/520 - 14s - loss: 0.5291 - sparse_categorical_accuracy: 0.7389 - val_loss: 0.4704 - val_sparse_categorical_accuracy: 0.7885\n",
      "Train for 520 steps, validate for 65 steps\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.175783). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.175783). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520/520 - 47s - loss: 0.4062 - sparse_categorical_accuracy: 0.8255 - val_loss: 0.2802 - val_sparse_categorical_accuracy: 0.9130\n",
      "Epoch 2/15\n",
      "520/520 - 46s - loss: 0.2540 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.1908 - val_sparse_categorical_accuracy: 0.9519\n",
      "Epoch 3/15\n",
      "520/520 - 42s - loss: 0.1730 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.1435 - val_sparse_categorical_accuracy: 0.9673\n",
      "Epoch 4/15\n",
      "520/520 - 41s - loss: 0.1269 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.1164 - val_sparse_categorical_accuracy: 0.9760\n",
      "Epoch 5/15\n",
      "520/520 - 41s - loss: 0.0956 - sparse_categorical_accuracy: 0.9767 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9774\n",
      "Epoch 6/15\n",
      "520/520 - 41s - loss: 0.0750 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.0866 - val_sparse_categorical_accuracy: 0.9788\n",
      "Epoch 7/15\n",
      "520/520 - 41s - loss: 0.0610 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.0779 - val_sparse_categorical_accuracy: 0.9832\n",
      "Epoch 8/15\n",
      "520/520 - 41s - loss: 0.0487 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.0711 - val_sparse_categorical_accuracy: 0.9861\n",
      "Epoch 9/15\n",
      "520/520 - 41s - loss: 0.0397 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0661 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 10/15\n",
      "520/520 - 41s - loss: 0.0315 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.0620 - val_sparse_categorical_accuracy: 0.9885\n",
      "Epoch 11/15\n",
      "520/520 - 41s - loss: 0.0262 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.0595 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 12/15\n",
      "520/520 - 41s - loss: 0.0213 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0570 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 13/15\n",
      "520/520 - 41s - loss: 0.0165 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0541 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 14/15\n",
      "520/520 - 41s - loss: 0.0135 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0535 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 15/15\n",
      "520/520 - 41s - loss: 0.0117 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0516 - val_sparse_categorical_accuracy: 0.9885\n",
      "====================== nnlm-en-dim128-with-normalization =======================\n",
      "Train for 520 steps, validate for 65 steps\n",
      "Epoch 1/25\n",
      "520/520 - 10s - loss: 0.6689 - sparse_categorical_accuracy: 0.6231 - val_loss: 0.5248 - val_sparse_categorical_accuracy: 0.7731\n",
      "Epoch 2/25\n",
      "520/520 - 10s - loss: 0.5528 - sparse_categorical_accuracy: 0.7170 - val_loss: 0.4666 - val_sparse_categorical_accuracy: 0.8207\n",
      "Epoch 3/25\n",
      "520/520 - 10s - loss: 0.5014 - sparse_categorical_accuracy: 0.7626 - val_loss: 0.4354 - val_sparse_categorical_accuracy: 0.8394\n",
      "Epoch 4/25\n",
      "520/520 - 9s - loss: 0.4828 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.4155 - val_sparse_categorical_accuracy: 0.8471\n",
      "Epoch 5/25\n",
      "520/520 - 9s - loss: 0.4645 - sparse_categorical_accuracy: 0.7852 - val_loss: 0.4006 - val_sparse_categorical_accuracy: 0.8538\n",
      "Epoch 6/25\n",
      "520/520 - 9s - loss: 0.4526 - sparse_categorical_accuracy: 0.7933 - val_loss: 0.3897 - val_sparse_categorical_accuracy: 0.8572\n",
      "Epoch 7/25\n",
      "520/520 - 9s - loss: 0.4449 - sparse_categorical_accuracy: 0.7950 - val_loss: 0.3810 - val_sparse_categorical_accuracy: 0.8577\n",
      "Epoch 8/25\n",
      "520/520 - 10s - loss: 0.4354 - sparse_categorical_accuracy: 0.8026 - val_loss: 0.3739 - val_sparse_categorical_accuracy: 0.8596\n",
      "Epoch 9/25\n",
      "520/520 - 10s - loss: 0.4368 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.3691 - val_sparse_categorical_accuracy: 0.8611\n",
      "Epoch 10/25\n",
      "520/520 - 9s - loss: 0.4365 - sparse_categorical_accuracy: 0.7965 - val_loss: 0.3649 - val_sparse_categorical_accuracy: 0.8596\n",
      "Epoch 11/25\n",
      "520/520 - 9s - loss: 0.4347 - sparse_categorical_accuracy: 0.8005 - val_loss: 0.3616 - val_sparse_categorical_accuracy: 0.8630\n",
      "Epoch 12/25\n",
      "520/520 - 9s - loss: 0.4358 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.3600 - val_sparse_categorical_accuracy: 0.8615\n",
      "Epoch 13/25\n",
      "520/520 - 9s - loss: 0.4337 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.3575 - val_sparse_categorical_accuracy: 0.8630\n",
      "Epoch 14/25\n",
      "520/520 - 10s - loss: 0.4354 - sparse_categorical_accuracy: 0.7985 - val_loss: 0.3562 - val_sparse_categorical_accuracy: 0.8630\n",
      "Epoch 15/25\n",
      "520/520 - 10s - loss: 0.4297 - sparse_categorical_accuracy: 0.8016 - val_loss: 0.3542 - val_sparse_categorical_accuracy: 0.8630\n",
      "Epoch 16/25\n",
      "520/520 - 9s - loss: 0.4299 - sparse_categorical_accuracy: 0.7977 - val_loss: 0.3528 - val_sparse_categorical_accuracy: 0.8625\n",
      "Epoch 17/25\n",
      "520/520 - 9s - loss: 0.4286 - sparse_categorical_accuracy: 0.8013 - val_loss: 0.3521 - val_sparse_categorical_accuracy: 0.8625\n",
      "Epoch 18/25\n",
      "520/520 - 9s - loss: 0.4286 - sparse_categorical_accuracy: 0.8029 - val_loss: 0.3508 - val_sparse_categorical_accuracy: 0.8606\n",
      "Epoch 19/25\n",
      "520/520 - 10s - loss: 0.4309 - sparse_categorical_accuracy: 0.7998 - val_loss: 0.3496 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 20/25\n",
      "520/520 - 10s - loss: 0.4271 - sparse_categorical_accuracy: 0.8044 - val_loss: 0.3492 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 21/25\n",
      "520/520 - 9s - loss: 0.4314 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.3481 - val_sparse_categorical_accuracy: 0.8630\n",
      "Epoch 22/25\n",
      "520/520 - 9s - loss: 0.4305 - sparse_categorical_accuracy: 0.8009 - val_loss: 0.3477 - val_sparse_categorical_accuracy: 0.8625\n",
      "Epoch 23/25\n",
      "520/520 - 9s - loss: 0.4284 - sparse_categorical_accuracy: 0.8015 - val_loss: 0.3474 - val_sparse_categorical_accuracy: 0.8630\n",
      "Epoch 24/25\n",
      "520/520 - 9s - loss: 0.4318 - sparse_categorical_accuracy: 0.8030 - val_loss: 0.3472 - val_sparse_categorical_accuracy: 0.8625\n",
      "Epoch 25/25\n",
      "520/520 - 10s - loss: 0.4275 - sparse_categorical_accuracy: 0.8019 - val_loss: 0.3467 - val_sparse_categorical_accuracy: 0.8630\n",
      "Train for 520 steps, validate for 65 steps\n",
      "Epoch 1/15\n",
      "520/520 - 23s - loss: 0.3355 - sparse_categorical_accuracy: 0.8578 - val_loss: 0.2161 - val_sparse_categorical_accuracy: 0.9413\n",
      "Epoch 2/15\n",
      "520/520 - 23s - loss: 0.2209 - sparse_categorical_accuracy: 0.9224 - val_loss: 0.1544 - val_sparse_categorical_accuracy: 0.9611\n",
      "Epoch 3/15\n",
      "520/520 - 23s - loss: 0.1523 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.1168 - val_sparse_categorical_accuracy: 0.9736\n",
      "Epoch 4/15\n",
      "520/520 - 23s - loss: 0.1137 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9779\n",
      "Epoch 5/15\n",
      "520/520 - 23s - loss: 0.0848 - sparse_categorical_accuracy: 0.9791 - val_loss: 0.0750 - val_sparse_categorical_accuracy: 0.9827\n",
      "Epoch 6/15\n",
      "520/520 - 23s - loss: 0.0663 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.0630 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 7/15\n",
      "520/520 - 22s - loss: 0.0511 - sparse_categorical_accuracy: 0.9880 - val_loss: 0.0541 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 8/15\n",
      "520/520 - 22s - loss: 0.0408 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0472 - val_sparse_categorical_accuracy: 0.9885\n",
      "Epoch 9/15\n",
      "520/520 - 23s - loss: 0.0329 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0430 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 10/15\n",
      "520/520 - 23s - loss: 0.0257 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0379 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 11/15\n",
      "520/520 - 23s - loss: 0.0207 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0358 - val_sparse_categorical_accuracy: 0.9918\n",
      "Epoch 12/15\n",
      "520/520 - 23s - loss: 0.0173 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0330 - val_sparse_categorical_accuracy: 0.9928\n",
      "Epoch 13/15\n",
      "520/520 - 23s - loss: 0.0141 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0309 - val_sparse_categorical_accuracy: 0.9928\n",
      "Epoch 14/15\n",
      "520/520 - 23s - loss: 0.0114 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0291 - val_sparse_categorical_accuracy: 0.9928\n",
      "Epoch 15/15\n",
      "520/520 - 23s - loss: 0.0091 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0280 - val_sparse_categorical_accuracy: 0.9928\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_formatted_code = \"run_models(model_urls, data_container, None)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_models(model_urls, data_container, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Wiki-words-250-with-normalization =======================\n",
      "Loading architecture & weights separately\n",
      "====================== nnlm-en-dim128-with-normalization =======================\n",
      "Loading architecture & weights separately\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_formatted_code = \"reports = evaluate_models(model_urls, data_container)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reports = evaluate_models(model_urls, data_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Wiki-words-250-with-normalization =======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1047\n",
      "           1       0.99      0.99      0.99      1033\n",
      "\n",
      "    accuracy                           0.99      2080\n",
      "   macro avg       0.99      0.99      0.99      2080\n",
      "weighted avg       0.99      0.99      0.99      2080\n",
      "\n",
      "====================== nnlm-en-dim128-with-normalization =======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1047\n",
      "           1       1.00      0.99      0.99      1033\n",
      "\n",
      "    accuracy                           0.99      2080\n",
      "   macro avg       0.99      0.99      0.99      2080\n",
      "weighted avg       0.99      0.99      0.99      2080\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_formatted_code = \"for model_name, report in reports.items():\\n    print(f\\\" {model_name} \\\".center(80, \\\"=\\\"))\\n    print(report)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_name, report in reports.items():\n",
    "    print(f\" {model_name} \".center(80, \"=\"))\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
